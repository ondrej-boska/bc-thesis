\chapter{Optimization}

\section{Genetic algorithm}

John Henry Holland first presented the concept of genetic algorithms to solve computationally hard problems in \textit{Adaptation in Natural and Artificial Systems} \cite{Holland:1975}. Starting with a \textit{population} formed with initial (in most cases random) solutions (\textit{individuals}), \textit{crossover} and \textit{mutation} operators are applied to gradually improve the fitness score of the population and thus find the best individual overall.

The most essential thing when designing a specific genetic algorithm is the encoding of an individual. Based on the encoding, we need to choose the genetic operators - \textit{crossover} and \textit{mutation}. The \textit{crossover} operator takes two random individuals (\textit{parents}) from the population and uses them to create two new individuals, which combine the properties of the parents. The \textit{mutation} operator takes only one individual and makes a change within him. The change should usually be small, and it can be either completely random or it can try to improve the individual using some heuristic (we will call this a \textit{smart mutation}). The operators are performed on an individual or pair of individuals with a given probability (so in each generation, only some individuals participate in crossover or are mutated).

After the operators are applied, the new population is created using the \textit{selection}. In our cases, the selection will either be a \textit{roulette wheel selection} or a \textit{tournament selection}. In the \textit{roulette wheel selection}, we sample individuals from the current population randomly, but the individuals are weighted using their fitness value (respectively with the inverse of the fitness value when minimizing). When using the \textit{tournament selection}, we take $n$ (usually 2 or 3) random individuals from the population and compare their fitness values. The best one is chosen and added to the new population. This process is repeated until the new population is fully populated.

Apart from using the \textit{roulette wheel} or \textit{tournament} selection, we will employ a strategy called \textit{elitism}. After the new population is sampled, we choose $n$ individuals randomly and replace them with the first $n$ best individuals from the old population. This ensures that the best individual in each population survives into the next generation.

We will introduce three different approaches on how to use the genetic algorithm meta-heuristic to solve (or approximate) the \textit{DARP}. 

\subsection{Individual as routes of stops}

\subsubsection*{Coding of an individual:}

The individual is encoded as a list of routes, where each route is a \textbf{list of stops} in the order the bus visits them.

The difference between the encoding of a solution and our individual is that the individual uses stops instead of groups to encode a route. The main reason for introducing this change was that maintaining the correctness of the solution after performing the genetic operators on it would be problematic. Making a (semi-)random change in the individual could easily end up in the violation of the \textit{handle every group exactly once constraint} or the \textit{bus capacity constraint}. Using stops instead of groups eliminates the problem of invalidating an individual (in some way) since there is no invalid individual. However, what can occur (and often will occur) is that we fail to pick up all the groups or ``forget'' to drop a group off. When this happens, we will consider the individual still valid but add a (large) penalty for every group not picked up or dropped off to the fitness value.

\subsubsection*{Fitness function:}

To evaluate the fitness function, we need to transform each individual into an instance of a solution. This will be done by a \textit{simulation}.

We simulate every route - at each stop, we pick up any group waiting for the bus at that stop and drop off every group present on the bus that can be dropped off. If multiple groups are waiting at the stop, but not all can fit into the bus, we prioritize the groups that are waiting longer. After the route simulation is complete, we remove every group not dropped off and stayed in the bus and add a \textit{not-dropped-off penalty} for each of them instead.

After we simulate all the routes, we check whether we picked up all the groups and add a \textit{not-picked-up penalty} for every ``unvisited'' group.

The \textit{not-picked-up penalty} constant should be larger than the \textit{not-dropped-off penalty} constant - when a change in an individual is made such that a group not picked-up earlier is now picked-up, but not dropped off, making the correction to handle that group validly is easier now (and thus the individual should be considered as a better one).

The resulting instance of the solution is then passed to the fitness function defined in the \hyperref[sec:fitness]{fitness function section}.

\subsubsection*{Initial population:}

We will present two different ways how to create the initial population.

The first way is generating purely random routes. The generator takes as a parameter the number of buses to use and the maximum allowed length of a route.

An alternative approach is to try to generate routes that are already feasible. We try to do this using a very simple heuristic. At each stop, we generate a set of reasonable next actions - picking up a new group or dropping off a group present on the bus. When considering groups to pick up, we only consider those whose departure time is close to the arrival time to their pick-up stop. For this, the generator takes a parameter defining how large this \textit{time window} should be. If there are no more available options, the bus ends the route by traveling to the depot. The generator can also be limited by parameters that define the maximum number of buses that can be used or the maximum number of groups that can be picked up within one route. 

\subsubsection*{Crossover:}

We will use a simple \textit{one-point crossover}. We take \textbf{one} random route from each individual, select a \textit{crossover point}, and swap the right parts of the routes between the individuals.

We decided to use the crossover on only one of the routes for each individual. This is because even a change in one route is usually quite a big change - it can easily result in not picking up or dropping off some groups and, therefore, making the new individual largely penalized. However, it also makes the genetic algorithm much more exploratory. We will discuss whether such crossover works well later by performing experiments with the crossover's probability rate.

\subsubsection*{Mutation:}

Unlike crossover, we have many options on what mutation operators to choose. We decided to implement many of them as \textit{``submutations''} and, at each mutation, choose one of them randomly. To make some of the \textit{``submutations''} more probable, we added weights to each of them, and the mutation function takes them as parameters. 

The possible \textit{``submutations''} are:
\begin{itemize}
    \setlength\itemsep{0pt}
    \item Reverse a random sub-route of a randomly chosen route. This is the main source of changing the stops' order.
    \item Delete a random stop from a randomly chosen route.
    \item Add a random stop to a randomly chosen route.
    \item Change a city to a random one in a randomly chosen route.
    \item Shuffle the routes within the solution. This can greatly impact the simulation when evaluating the fitness function (since each group is picked up by the first bus (in the simulation order) that arrives at their stop at the right time, if more buses travel through the same stop, groups on that stop can be picked up by a completely different bus).
    \item ``Smart mutation'' - depending on the quality of the individual, it either adds a place not visited in any of the routes to a randomly chosen route (trying to maximize the number of groups picked up), completes a "coordinate pair" (i.\ e.\ adds a stop to the route where the bus can drop off the passengers) or it tries to perform a swap of a group between 2 routes.
\end{itemize}

\xxx{Subsection: Tuning the hyperparameters}

\subsection{Individual as separate clustering and routing}

\xxx{todo}

\subsection{Individual as only clustering with heuristic routing}

\xxx{todo}

\section{Ant Colony Optimization}

\xxx{General meta-heuristics description}

\subsection{Individual as the solution itself}

\xxx{reformulate}

\subsubsection*{Coding of an individual:}
The individual is represented as a list of routes, where each route is an ordered list of groups. Each group is represented twice, once for the pick-up and once for the drop-off. Each route implicitly starts and ends at the depot.

\subsubsection*{Pheromone matrix}
The pheromone matrix is of size $2|G| \times 2|G| + 1$, where $G$ is the set of all groups. For each group with id $i$, the pheromone at index $2i - 1$ represents the probability of the group being picked up, and the pheromone at index $2i$ represents the likelihood of the group being dropped off. The last element of the matrix represents the probability of the bus moving to the depot (and thus ending its route).

\subsubsection*{Fitness function:}
The fitness function is calculated similarly to the genetic algorithm approach, with the only difference being that the routes of the individual are now encoded as lists of groups (where each group is represented twice, once for the pick-up and once for the drop-off), rather than lists of stops.

\subsubsection*{Attractiveness:}
An essential part of the ACO algorithm is the "attractiveness" - a simple heuristic value for each edge in the graph. Here, the attractiveness is calculated as the sum of the inverse of the distance and the inverse of the difference between the group's departure time and the time the bus arrives at the stop. Additionally, attractiveness is raised by a constant parameter value if the edge represents dropping off a group waiting in the bus (this tries to minimize the delays by dropping off groups as soon as possible). Also, when the attractiveness is calculated for the depot, it is raised by a parameter value (usually the length of the route multiplied by some parametric constant) to encourage the bus to return to the depot (and avoid making the routes too long).

\subsubsection*{Constructing new solutions:}
For every ant, we generate a solution as a list of routes. Each route starts at the depot. At each stop, the set of available subsequent nodes is calculated as a union of pick-up nodes for groups not picked up by any bus yet and drop-off nodes for groups present in the bus. If there are no groups on the bus, the depot node is added to the set of available nodes instead (this ensures that the bus cannot end its route with passengers still onboard). Each probability is then calculated (as $pheromone^\alpha \cdot attractivness^\beta$), and the next stop is chosen using the roulette wheel selection. New routes are then constructed by repeating this process until all groups are handled.
